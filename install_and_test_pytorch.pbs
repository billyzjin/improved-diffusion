#!/bin/bash -l
#PBS -A Brownian_bandits
#PBS -l select=1:system=polaris
#PBS -l walltime=0:30:00
#PBS -l filesystems=home:eagle
#PBS -q debug
#PBS -N install_pytorch

echo "=========================================="
echo "INSTALLING PYTORCH AND TESTING"
echo "=========================================="
echo "Job ID: $PBS_JOBID"
echo "Host: $(hostname)"
echo "Date: $(date)"
echo "Working directory: $(pwd)"
echo "=========================================="

# Check if we're on a compute node
if [ -n "$PBS_NODEFILE" ]; then
    echo "Running on compute node(s):"
    cat $PBS_NODEFILE
    echo "Number of nodes: $(wc -l < $PBS_NODEFILE)"
else
    echo "ERROR: Running on login node - this shouldn't happen!"
    exit 1
fi

echo "=========================================="
echo "LOADING PYTHON MODULE"
echo "=========================================="

# Load Python module
module load cray-python/3.11.7
echo "Python version: $(python3 --version)"

echo "=========================================="
echo "INSTALLING PYTORCH"
echo "=========================================="

# Install PyTorch with CUDA support
echo "Installing PyTorch with CUDA 12.1 support..."
python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

echo "=========================================="
echo "TESTING PYTORCH INSTALLATION"
echo "=========================================="

# Test PyTorch installation
python3 << 'PYEOF'
import torch
import numpy as np
import time

print("Testing PyTorch installation...")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA device count: {torch.cuda.device_count()}")
    print(f"Current CUDA device: {torch.cuda.current_device()}")
    print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
    
    # Test GPU computation
    print("\nTesting GPU computation...")
    x = torch.randn(1000, 1000, device='cuda')
    start_time = time.time()
    y = torch.matmul(x, x)
    torch.cuda.synchronize()  # Wait for GPU to finish
    end_time = time.time()
    
    print(f"GPU matrix multiplication time: {end_time - start_time:.4f} seconds")
    print(f"Result shape: {y.shape}")
    print(f"Result device: {y.device}")
else:
    print("CUDA not available, testing CPU computation...")
    x = torch.randn(1000, 1000)
    start_time = time.time()
    y = torch.matmul(x, x)
    end_time = time.time()
    
    print(f"CPU matrix multiplication time: {end_time - start_time:.4f} seconds")

print("PyTorch test completed successfully!")
PYEOF

echo "=========================================="
echo "INSTALLATION AND TEST COMPLETED!"
echo "=========================================="
