#!/bin/bash -l
#PBS -A Brownian_bandits
#PBS -l select=1:system=polaris
#PBS -l walltime=0:20:00
#PBS -l filesystems=home:eagle
#PBS -q debug
#PBS -N test_system_cuda

echo "=========================================="
echo "TESTING WITH SYSTEM CUDA MODULES"
echo "=========================================="
echo "Job ID: $PBS_JOBID"
echo "Host: $(hostname)"
echo "Date: $(date)"
echo "Working directory: $(pwd)"
echo "=========================================="

# Check if we're on a compute node
if [ -n "$PBS_NODEFILE" ]; then
    echo "Running on compute node(s):"
    cat $PBS_NODEFILE
    echo "Number of nodes: $(wc -l < $PBS_NODEFILE)"
else
    echo "ERROR: Running on login node - this shouldn't happen!"
    exit 1
fi

echo "=========================================="
echo "LOADING MODULES"
echo "=========================================="

# Load Python module
echo "Loading Python module..."
module load cray-python/3.11.7
echo "Python version: $(python3 --version)"

# Load CUDA module (use newest version)
echo "Loading CUDA 12.6 module..."
module load cuda/12.6
echo "CUDA version: $(nvcc --version 2>/dev/null || echo 'nvcc not found')"

# Load nvidia module (use newest version)
echo "Loading nvidia 24.11 module..."
module load nvidia/24.11
echo "NVIDIA driver version: $(nvidia-smi --version 2>/dev/null || echo 'nvidia-smi not found')"

echo "=========================================="
echo "CHECKING PYTHON PACKAGES"
echo "=========================================="

# Check what Python packages are available
echo "Available Python packages:"
python3 -m pip list 2>/dev/null | head -20

echo "=========================================="
echo "INSTALLING PYTORCH"
echo "=========================================="

# Install PyTorch with CUDA support (CUDA 12.1 is compatible with CUDA 12.6)
echo "Installing PyTorch with CUDA 12.1 support..."
python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

echo "=========================================="
echo "TESTING PYTORCH WITH CUDA"
echo "=========================================="

# Test PyTorch installation
python3 << 'PYEOF'
import torch
import numpy as np
import time

print("Testing PyTorch installation...")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDA device count: {torch.cuda.device_count()}")
    print(f"Current CUDA device: {torch.cuda.current_device()}")
    print(f"CUDA device name: {torch.cuda.get_device_name(0)}")
    
    # Test GPU computation
    print("\nTesting GPU computation...")
    x = torch.randn(1000, 1000, device='cuda')
    start_time = time.time()
    y = torch.matmul(x, x)
    torch.cuda.synchronize()  # Wait for GPU to finish
    end_time = time.time()
    
    print(f"GPU matrix multiplication time: {end_time - start_time:.4f} seconds")
    print(f"Result shape: {y.shape}")
    print(f"Result device: {y.device}")
    
    # Test memory usage
    print(f"GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
    print(f"GPU memory cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")
else:
    print("CUDA not available, testing CPU computation...")
    x = torch.randn(1000, 1000)
    start_time = time.time()
    y = torch.matmul(x, x)
    end_time = time.time()
    
    print(f"CPU matrix multiplication time: {end_time - start_time:.4f} seconds")

print("PyTorch test completed successfully!")
PYEOF

echo "=========================================="
echo "SYSTEM CUDA TEST COMPLETED!"
echo "=========================================="
